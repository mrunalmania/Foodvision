# Foodvision
Implement Transformer architecture in computer vision task (Object Detection) and compare the ViT (Vision Transformer) feature extractor and EffnetB2 models, achieving prediction accuracy of more than 95% and prediction time of less than 30FPS (Real-time). Also, host the whole model on hugging face spaces and put it into production.


## Deploy the model on the huggingface spaces:
``` https://huggingface.co/spaces/mrunalmania/FoodVision-Big ```

## What is the workflow?
I have leveraged the Pytorch torchvision library to implement the ViT (vision transformer) and EffecientNet B2 model and then compare the results for both.

